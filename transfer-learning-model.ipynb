{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW4UmSUYbGcv"
      },
      "source": [
        "# StyleGan2 Requires TF 1.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "u9BqpZBVZB_E",
        "outputId": "4bdab5aa-a38d-456c-aa01-d0f44528c67a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n",
            "Requirement already satisfied: numpy==1.19 in /usr/local/lib/python3.7/dist-packages (1.19.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.19.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install numpy==1.19\n",
        "\n",
        "import numpy as np\n",
        "np.version.version"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wmdvOOnbMuq"
      },
      "source": [
        "# Connect to Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-18mkiMPZRbx",
        "outputId": "c1b686dc-ff31-4154-bdbe-a5b1883eeb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "\n",
        "content_path = Path('/').absolute() / 'content'\n",
        "drive_path = content_path / 'drive'\n",
        "drive.mount(str(drive_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-hz1KudbPH8"
      },
      "source": [
        "# Setup Project Structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1JIRt0nbTm4",
        "outputId": "0b4fd78c-e48f-46b7-f573-99a10fcbfff0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/cs1430-final\n"
          ]
        }
      ],
      "source": [
        "repo = 'https://github.com/NVlabs/stylegan2-ada' # GAN we are going to retrain\n",
        "root = drive_path / 'MyDrive' / 'cs1430-final' # root folder of our project\n",
        "reset = False # change this if you imported a new images.zip file\n",
        "\n",
        "if not root.is_dir(): # create root folder\n",
        "  %mkdir $root\n",
        "\n",
        "%cd $root\n",
        "\n",
        "data_dir = root / 'data'          # dir paths\n",
        "res_dir = root / 'results'\n",
        "gan_dir = root / 'stylegan2-ada'\n",
        "\n",
        "# create the dirs in project setup\n",
        "\n",
        "if reset:\n",
        "  %rm -rf $data_dir && rm -rf $res_dir\n",
        "\n",
        "if not data_dir.is_dir(): \n",
        "  %mkdir $data_dir\n",
        "\n",
        "if not res_dir.is_dir(): \n",
        "  %mkdir $res_dir\n",
        "\n",
        "if not gan_dir.is_dir(): \n",
        "  !git clone $repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-t1N_4sA1xAD"
      },
      "source": [
        "## **Important:** drag the images.zip file into the root folder in your drive before moving on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W8A7yJg4d9dW"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBDJgS8eZguR",
        "outputId": "34b9f7b8-7dc4-4a13-ae05-db446bf72504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images...\n",
            "Extraction completed\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "if not (data_dir / 'images').is_dir(): # if we have not unzipped the images yet\n",
        "  print(\"Extracting images...\")\n",
        "\n",
        "  with zipfile.ZipFile(str(root / ('images.zip')), 'r') as zip_ref: # unzip images into ./data/images\n",
        "    zip_ref.extractall(str(data_dir))\n",
        "    \n",
        "  print('Extraction completed')\n",
        "else:\n",
        "  print(\"Images already exist!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAlSTMI3eHtz"
      },
      "source": [
        "Convert to TF Records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laOCNgw2ZjEp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd05643a-9b9a-4ffa-be00-23114ad7d640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading images from \"/content/drive/MyDrive/cs1430-final/data/images\"\n",
            "Creating dataset \"/content/drive/MyDrive/cs1430-final/data/tfr\"\n",
            "0 / 102\rstylegan2-ada/dataset_tool.py:96: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "  'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n",
            "Added 102 images.\n"
          ]
        }
      ],
      "source": [
        "\"\"\"\n",
        "This is the data format required by the GAN.\n",
        "This cell will convert our images into the tf records.\n",
        "\"\"\"\n",
        "\n",
        "image_dir = data_dir / 'images'\n",
        "tfr_dir = data_dir / 'tfr'\n",
        "regenerate = True # change this if you imported a new images.zip file\n",
        "if tfr_dir.is_dir() and regenerate:\n",
        "    %rm -rf $tfr_dir\n",
        "    %mkdir $tfr_dir\n",
        "elif not tfr_dir.is_dir(): \n",
        "  %mkdir $tfr_dir    \n",
        "\n",
        "!python stylegan2-ada/dataset_tool.py create_from_images $tfr_dir $image_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsI9IitvhpTx"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK70ikR2ZmL8",
        "outputId": "ca1b5b06-a718-4e64-aff8-ff4c6ca9f682"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tcmalloc: large alloc 4294967296 bytes == 0x6b42000 @  0x7fe1b269d001 0x7fe1af8c41af 0x7fe1af91ac23 0x7fe1af91ba87 0x7fe1af9bd823 0x5936cc 0x548c51 0x5127f1 0x549e0e 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x4bca8a 0x5134a6 0x549576 0x4bca8a 0x5134a6 0x549e0e 0x4bca8a 0x5134a6 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7fdff539a000 @  0x7fe1b269b1e7 0x7fe1af8c40ce 0x7fe1af91acf5 0x7fe1af91af4f 0x7fe1af9bd673 0x5936cc 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7fdef4398000 @  0x7fe1b269b1e7 0x7fe1af8c40ce 0x7fe1af91acf5 0x7fe1af91af4f 0x7fe172ef0235 0x7fe172873792 0x7fe172873d42 0x7fe17282caee 0x59371f 0x548c51 0x51566f 0x593dd7 0x511e2c 0x549e0e 0x4bcb19 0x5134a6 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x4bcb19 0x59c019 0x595ef6 0x5134a6 0x549576 0x593fce\n",
            "\n",
            "Training options:\n",
            "{\n",
            "  \"G_args\": {\n",
            "    \"func_name\": \"training.networks.G_main\",\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"mapping_layers\": 2,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"D_args\": {\n",
            "    \"func_name\": \"training.networks.D_main\",\n",
            "    \"mbstd_group_size\": 4,\n",
            "    \"fmap_base\": 16384,\n",
            "    \"fmap_max\": 512,\n",
            "    \"num_fp16_res\": 4,\n",
            "    \"conv_clamp\": 256\n",
            "  },\n",
            "  \"G_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"D_opt_args\": {\n",
            "    \"beta1\": 0.0,\n",
            "    \"beta2\": 0.99,\n",
            "    \"learning_rate\": 0.0025\n",
            "  },\n",
            "  \"loss_args\": {\n",
            "    \"func_name\": \"training.loss.stylegan2\",\n",
            "    \"r1_gamma\": 6.5536\n",
            "  },\n",
            "  \"augment_args\": {\n",
            "    \"class_name\": \"training.augment.AdaptiveAugment\",\n",
            "    \"tune_heuristic\": \"rt\",\n",
            "    \"tune_target\": 0.6,\n",
            "    \"apply_func\": \"training.augment.augment_pipeline\",\n",
            "    \"apply_args\": {\n",
            "      \"xflip\": 1,\n",
            "      \"rotate90\": 1,\n",
            "      \"xint\": 1,\n",
            "      \"scale\": 1,\n",
            "      \"rotate\": 1,\n",
            "      \"aniso\": 1,\n",
            "      \"xfrac\": 1,\n",
            "      \"brightness\": 1,\n",
            "      \"contrast\": 1,\n",
            "      \"lumaflip\": 1,\n",
            "      \"hue\": 1,\n",
            "      \"saturation\": 1\n",
            "    },\n",
            "    \"tune_kimg\": 100\n",
            "  },\n",
            "  \"num_gpus\": 1,\n",
            "  \"image_snapshot_ticks\": 2,\n",
            "  \"network_snapshot_ticks\": 2,\n",
            "  \"train_dataset_args\": {\n",
            "    \"path\": \"/content/drive/MyDrive/cs1430-final/data/tfr\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"resolution\": 512,\n",
            "    \"mirror_augment\": true\n",
            "  },\n",
            "  \"metric_arg_list\": [],\n",
            "  \"metric_dataset_args\": {\n",
            "    \"path\": \"/content/drive/MyDrive/cs1430-final/data/tfr\",\n",
            "    \"max_label_size\": 0,\n",
            "    \"resolution\": 512,\n",
            "    \"mirror_augment\": true\n",
            "  },\n",
            "  \"total_kimg\": 25000,\n",
            "  \"minibatch_size\": 8,\n",
            "  \"minibatch_gpu\": 8,\n",
            "  \"G_smoothing_kimg\": 2.5,\n",
            "  \"G_smoothing_rampup\": null,\n",
            "  \"resume_pkl\": \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/transfer-learning-source-nets/ffhq-res1024-mirror-stylegan2-noaug.pkl\",\n",
            "  \"run_dir\": \"/content/drive/MyDrive/cs1430-final/results/00005-tfr-mirror-auto1-bgc-resumeffhq1024\"\n",
            "}\n",
            "\n",
            "Output directory:  /content/drive/MyDrive/cs1430-final/results/00005-tfr-mirror-auto1-bgc-resumeffhq1024\n",
            "Training data:     /content/drive/MyDrive/cs1430-final/data/tfr\n",
            "Training length:   25000 kimg\n",
            "Resolution:        512\n",
            "Number of GPUs:    1\n",
            "\n",
            "Creating output directory...\n",
            "Loading training set...\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7fdde8972000 @  0x7fe1b269d001 0x7fe1af8c41af 0x7fe1af91ac23 0x7fe1af91ba87 0x7fe1af9bd823 0x5936cc 0x548c51 0x5127f1 0x549e0e 0x4bca8a 0x532b86 0x594a96 0x548cc1 0x5127f1 0x549576 0x4bca8a 0x5134a6 0x549576 0x4bca8a 0x5134a6 0x549e0e 0x4bca8a 0x5134a6 0x593dd7 0x5118f8 0x549576 0x604173 0x5f5506 0x5f8c6c 0x5f9206 0x64faf2\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7fdce8172000 @  0x7fe1b269b1e7 0x7fe1af8c40ce 0x7fe1af91acf5 0x7fe1af91af4f 0x7fe1af9bd673 0x5936cc 0x548c51 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x549576 0x593fce 0x548ae9 0x5127f1 0x593dd7 0x5118f8 0x549576 0x593fce 0x548ae9 0x51566f 0x549576 0x593fce 0x548ae9 0x5127f1 0x549e0e\n",
            "tcmalloc: large alloc 4294967296 bytes == 0x7fdce8172000 @  0x7fe1b269b1e7 0x7fe1af8c40ce 0x7fe1af91acf5 0x7fe1af91af4f 0x7fe172ef0235 0x7fe172873792 0x7fe172873d42 0x7fe17282caee 0x59371f 0x548c51 0x51566f 0x593dd7 0x511e2c 0x549e0e 0x4bcb19 0x5134a6 0x549576 0x593fce 0x511e2c 0x549e0e 0x593fce 0x511e2c 0x593dd7 0x511e2c 0x549576 0x4bcb19 0x59c019 0x595ef6 0x5134a6 0x549576 0x593fce\n",
            "Image shape: [3, 512, 512]\n",
            "Label shape: [0]\n",
            "\n",
            "Constructing networks...\n",
            "Setting up TensorFlow plugin \"fused_bias_act.cu\": Loading... Done.\n",
            "Setting up TensorFlow plugin \"upfirdn_2d.cu\": Loading... Done.\n"
          ]
        }
      ],
      "source": [
        "snapshot_count = 2 # how often should the model generate samples and a .pkl file\n",
        "mirrored = True # should the images be mirrored left to right?\n",
        "mirroredY = False # should the images be mirrored top to bottom?\n",
        "metric_list = None # metrics?\n",
        "augs = 'bgc' # augments\n",
        "\n",
        "resume_from = 'ffhq1024'\n",
        "\n",
        "!python stylegan2-ada/train.py \\\n",
        "    --outdir=$res_dir \\\n",
        "    --data=$tfr_dir \\\n",
        "    --resume=$resume_from \\\n",
        "    --snap=$snapshot_count \\\n",
        "    --augpipe=$augs \\\n",
        "    --mirror=$mirrored \\\n",
        "    --metrics=$metric_list\n",
        "\n",
        "\n",
        "python3.7 stylegan2-ada/train.py --outdir=res --data=data/tfr --resume='ffhq1024' --snap=2 --augpipe='bgc' --mirror=true --metrics=None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6tMc2v6l080"
      },
      "source": [
        "# Generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swRas4IzaXdd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "outputId": "f6d1900b-9e12-4d28-9d22-765753f7418f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opensimplex in /usr/local/lib/python3.7/dist-packages (0.4.2)\n",
            "Collecting numpy>=1.20\n",
            "  Using cached numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.0\n",
            "    Uninstalling numpy-1.19.0:\n",
            "      Successfully uninstalled numpy-1.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lucid 0.3.10 requires umap-learn, which is not installed.\n",
            "tensorflow 1.15.2 requires gast==0.2.2, but you have gast 0.5.3 which is incompatible.\n",
            "lucid 0.3.10 requires numpy<=1.19, but you have numpy 1.21.6 which is incompatible.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.15.2 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed numpy-1.21.6\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%pip install opensimplex"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python stylegan2-ada/generate.py -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Q8LiFf6bZ0k",
        "outputId": "8c65af82-c7b5-4ba5-a08a-0f2258dca85c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: generate.py [-h] --network NETWORK_PKL\n",
            "                   (--seeds SEEDS | --dlatents DLATENTS_NPZ)\n",
            "                   [--trunc TRUNCATION_PSI] [--class CLASS_IDX] --outdir DIR\n",
            "\n",
            "Generate images using pretrained network pickle.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --network NETWORK_PKL\n",
            "                        Network pickle filename\n",
            "  --seeds SEEDS         List of random seeds\n",
            "  --dlatents DLATENTS_NPZ\n",
            "                        Generate images for saved dlatents\n",
            "  --trunc TRUNCATION_PSI\n",
            "                        Truncation psi (default: 0.5)\n",
            "  --class CLASS_IDX     Class label (default: unconditional)\n",
            "  --outdir DIR          Where to save the output images\n",
            "\n",
            "examples:\n",
            "\n",
            "  # Generate curated MetFaces images without truncation (Fig.10 left)\n",
            "  python generate.py --outdir=out --trunc=1 --seeds=85,265,297,849 \\\n",
            "      --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metfaces.pkl\n",
            "\n",
            "  # Generate uncurated MetFaces images with truncation (Fig.12 upper left)\n",
            "  python generate.py --outdir=out --trunc=0.7 --seeds=600-605 \\\n",
            "      --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/metfaces.pkl\n",
            "\n",
            "  # Generate class conditional CIFAR-10 images (Fig.17 left, Car)\n",
            "  python generate.py --outdir=out --trunc=1 --seeds=0-35 --class=1 \\\n",
            "      --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/cifar10.pkl\n",
            "\n",
            "  # Render image from projected latent vector\n",
            "  python generate.py --outdir=out --dlatents=out/dlatents.npz \\\n",
            "      --network=https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada/pretrained/ffhq.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTE9Zta0aZBE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e3142c2-a0ed-4cc4-bf7c-d073b6b9f6e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading networks from \"/content/drive/MyDrive/cs1430-final/results/model/res.pkl\"...\n",
            "Traceback (most recent call last):\n",
            "  File \"stylegan2-ada/generate.py\", line 121, in <module>\n",
            "    main()\n",
            "  File \"stylegan2-ada/generate.py\", line 116, in main\n",
            "    generate_images(**vars(args))\n",
            "  File \"stylegan2-ada/generate.py\", line 27, in generate_images\n",
            "    with dnnlib.util.open_url(network_pkl) as fp:\n",
            "  File \"/content/drive/MyDrive/cs1430-final/stylegan2-ada/dnnlib/util.py\", line 386, in open_url\n",
            "    return url if return_filename else open(url, \"rb\")\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/cs1430-final/results/model/res.pkl'\n"
          ]
        }
      ],
      "source": [
        "from numpy import random\n",
        "seed_init = random.randint(10000)\n",
        "nbr_images = 6 - 1\n",
        "seeds = \"{}-{}\".format(seed_init, seed_init + nbr_images) #seed_init + \"-\" + seed_init + nbr_images\n",
        "\n",
        "\n",
        "generation_from = res_dir / 'model' / 'res.pkl'\n",
        "\n",
        "!python stylegan2-ada/generate.py \\\n",
        "    --outdir=$res_dir \\\n",
        "    --trunc=0.7 \\\n",
        "    --seeds=0-10 \\\n",
        "    --network=$generation_from"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "cs1430.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}